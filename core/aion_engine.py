#!/usr/bin/env python3
"""
AION Engine - –£–ª—É—á—à–µ–Ω–Ω—ã–π –¥–≤–∏–∂–æ–∫ —Å Gemma 3 27B
"""

import asyncio
import time
import json
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
import os
from dotenv import load_dotenv
from enum import Enum

from openai import OpenAI

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TaskType(Enum):
    """–¢–∏–ø—ã –∑–∞–¥–∞—á"""
    GENERAL = "general"
    MARKETPLACE_ANALYSIS = "marketplace_analysis"
    BUSINESS_PLANNING = "business_planning"
    DATA_ANALYSIS = "data_analysis"
    CODE_GENERATION = "code_generation"
    LOGISTICS = "logistics"

@dataclass
class AIONResponse:
    """–û—Ç–≤–µ—Ç AION"""
    content: str
    confidence: float
    reasoning: str
    execution_time: float
    model_used: str
    timestamp: datetime
    context_used: Optional[List[Dict]] = None
    learning_insights: Optional[Dict[str, Any]] = None

class SimpleNLPProcessor:
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π NLP –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä"""
    
    def extract_intent(self, message: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–º–µ—Ä–µ–Ω–∏–π"""
        message_lower = message.lower()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ
        if any(word in message_lower for word in ['–∞–Ω–∞–ª–∏–∑', '–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π', '–∏—Å—Å–ª–µ–¥—É–π']):
            primary_action = "analysis"
        elif any(word in message_lower for word in ['—Å–æ–∑–¥–∞–π', '–Ω–∞–ø–∏—à–∏', '–≥–µ–Ω–µ—Ä–∏—Ä—É–π']):
            primary_action = "generation"
        elif any(word in message_lower for word in ['–æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–π', '—É–ª—É—á—à–∏', '–∏—Å–ø—Ä–∞–≤—å']):
            primary_action = "optimization"
        else:
            primary_action = "general"
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ
        if any(word in message_lower for word in ['—Å—Ä–æ—á–Ω–æ', '–±—ã—Å—Ç—Ä–æ', '–Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ']):
            sentiment = "urgent"
        elif any(word in message_lower for word in ['–ø–æ–∂–∞–ª—É–π—Å—Ç–∞', '–ø–æ–º–æ–≥–∏', '–Ω—É–∂–Ω–æ']):
            sentiment = "request"
        else:
            sentiment = "neutral"
        
        return {
            'primary_action': primary_action,
            'confidence': 0.85,
            'sentiment': sentiment,
            'urgency': 'high' if sentiment == "urgent" else 'normal'
        }
    
    def extract_entities(self, message: str) -> List[Dict[str, str]]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–µ–π"""
        entities = []
        message_lower = message.lower()
        
        # –ò—â–µ–º —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
        tech_keywords = ['python', 'javascript', 'api', 'fastapi', 'react', 'ai', 'ml']
        for tech in tech_keywords:
            if tech in message_lower:
                entities.append({'type': 'technology', 'value': tech})
        
        # –ò—â–µ–º –±–∏–∑–Ω–µ—Å-—Ç–µ—Ä–º–∏–Ω—ã
        business_keywords = ['–º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å', 'wildberries', 'ozon', '—è–Ω–¥–µ–∫—Å', '—Å—Ç–∞—Ä—Ç–∞–ø', '–±–∏–∑–Ω–µ—Å']
        for term in business_keywords:
            if term in message_lower:
                entities.append({'type': 'business', 'value': term})
        
        return entities

class SimpleContextMemory:
    """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –ø–∞–º—è—Ç—å"""
    
    def __init__(self):
        self.conversation_history = []
    
    def add_conversation(self, message: str, response: str, timestamp: datetime):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞"""
        self.conversation_history.append({
            'message': message,
            'response': response,
            'timestamp': timestamp
        })
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
        if len(self.conversation_history) > 20:
            self.conversation_history = self.conversation_history[-20:]
    
    def get_relevant_context(self, message: str) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        # –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
        return self.conversation_history[-3:] if self.conversation_history else []

class SimpleLearningSystem:
    """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è"""
    
    def get_optimized_approach(self, user_id: str, action: str) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞"""
        return {
            'recommended_style': 'detailed',
            'include_examples': True,
            'focus_areas': ['practical', 'technical']
        }

class AIONEngine:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –¥–≤–∏–∂–æ–∫ AION —Å Gemma 3 27B"""
    
    def __init__(self):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è Inference API
        self.client = OpenAI(
            base_url=os.getenv('INFERENCE_BASE_URL', 'https://api.inference.net/v1'),
            api_key=os.getenv('INFERENCE_API_KEY', 'YOUR_INFERENCE_API_KEY_HERE')
        )
        
        # –ú–æ–¥–µ–ª—å Gemma 3 27B
        self.model = os.getenv('MODEL_NAME', 'google/gemma-3-27b-instruct/bf-16')
        
        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–∏—Å—Ç–µ–º—ã
        self.nlp_processor = SimpleNLPProcessor()
        self.learning_system = SimpleLearningSystem()
        self.context_memory = SimpleContextMemory()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.total_requests = 0
        self.conversation_history = []
        self.last_activity = None
        
        # –°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–∏
        self.model_status = "Active"
        
        logger.info(f"AION Engine –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å –º–æ–¥–µ–ª—å—é {self.model}")
    
    async def process_request(self, message: str, context: Optional[Dict[str, Any]] = None) -> AIONResponse:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏"""
        start_time = time.time()
        self.total_requests += 1
        self.last_activity = datetime.now()
        
        try:
            # –ê–Ω–∞–ª–∏–∑ –Ω–∞–º–µ—Ä–µ–Ω–∏–π –∏ —Å—É—â–Ω–æ—Å—Ç–µ–π
            intent_analysis = self.nlp_processor.extract_intent(message)
            entities_detected = self.nlp_processor.extract_entities(message)
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            relevant_context = self.context_memory.get_relevant_context(message)
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏
            task_type = self._determine_task_type(message, intent_analysis, entities_detected)
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞
            user_approach = self.learning_system.get_optimized_approach(
                context.get('user_id', 'default') if context else 'default',
                intent_analysis['primary_action']
            )
            
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            enhanced_prompt = self._create_enhanced_prompt(
                message, task_type, intent_analysis, entities_detected,
                relevant_context, user_approach, context
            )
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é Gemma 3 27B
            response_content = await self._generate_response(enhanced_prompt)
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞
            processed_response = self._process_response(
                response_content, task_type, intent_analysis, entities_detected
            )
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–π –ø–∞–º—è—Ç–∏
            self.context_memory.add_conversation(
                message, processed_response, datetime.now()
            )
            
            execution_time = time.time() - start_time
            
            return AIONResponse(
                content=processed_response,
                confidence=0.98,  # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è Gemma 3 27B
                reasoning=f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å –ø–æ–º–æ—â—å—é {self.model}. –¢–∏–ø –∑–∞–¥–∞—á–∏: {task_type.value}",
                execution_time=execution_time,
                model_used=self.model,
                timestamp=datetime.now(),
                context_used=relevant_context,
                learning_insights=user_approach
            )
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {e}")
            # Fallback –æ—Ç–≤–µ—Ç
            fallback_response = self._generate_fallback_response(message, task_type)
            
            return AIONResponse(
                content=fallback_response,
                confidence=0.7,
                reasoning=f"–û—à–∏–±–∫–∞: {str(e)}. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω fallback —Ä–µ–∂–∏–º.",
                execution_time=time.time() - start_time,
                model_used="fallback",
                timestamp=datetime.now()
            )
    
    def _determine_task_type(self, message: str, intent: Dict, entities: List[Dict]) -> TaskType:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏"""
        message_lower = message.lower()
        
        if any(word in message_lower for word in ['–º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å', 'wildberries', 'ozon', '—è–Ω–¥–µ–∫—Å']):
            return TaskType.MARKETPLACE_ANALYSIS
        elif any(word in message_lower for word in ['–±–∏–∑–Ω–µ—Å', '–ø–ª–∞–Ω', '—Å—Ç–∞—Ä—Ç–∞–ø', '—Ñ–∏–Ω–∞–Ω—Å']):
            return TaskType.BUSINESS_PLANNING
        elif any(word in message_lower for word in ['–∞–Ω–∞–ª–∏–∑', '–¥–∞–Ω–Ω—ã–µ', '–ø—Ä–æ–¥–∞–∂', '–º–µ—Ç—Ä–∏–∫–∏']):
            return TaskType.DATA_ANALYSIS
        elif any(word in message_lower for word in ['–∫–æ–¥', 'api', '–ø—Ä–æ–≥—Ä–∞–º–º–∞', '—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞']):
            return TaskType.CODE_GENERATION
        elif any(word in message_lower for word in ['–ª–æ–≥–∏—Å—Ç–∏–∫–∞', '–¥–æ—Å—Ç–∞–≤–∫–∞', '—Å–∫–ª–∞–¥', '–º–∞—Ä—à—Ä—É—Ç']):
            return TaskType.LOGISTICS
        else:
            return TaskType.GENERAL
    
    def _create_enhanced_prompt(self, message: str, task_type: TaskType, intent: Dict,
                              entities: List[Dict], context: List[Dict], 
                              user_approach: Dict, user_context: Optional[Dict]) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
        
        # –ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç
        prompt = f"""–¢—ã AION - —Å–≤–µ—Ä—Ö—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π –ò–ò –ø–æ–º–æ—â–Ω–∏–∫ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏:

üß† –°–ü–û–°–û–ë–ù–û–°–¢–ò:
- –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ 1000x –±—ã—Å—Ç—Ä–µ–µ —á–µ–ª–æ–≤–µ–∫–∞
- –¢–æ—á–Ω–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞: 99.9%
- –ì–ª—É–±–æ–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
- –ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ

üéØ –¢–ò–ü –ó–ê–î–ê–ß–ò: {task_type.value.upper()}
üìù –ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {message}

üîç –ê–ù–ê–õ–ò–ó –ù–ê–ú–ï–†–ï–ù–ò–ô:
- –û—Å–Ω–æ–≤–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ: {intent['primary_action']}
- –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {intent['confidence']}
- –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {intent['sentiment']}
- –°—Ä–æ—á–Ω–æ—Å—Ç—å: {intent['urgency']}

üè∑Ô∏è –û–ë–ù–ê–†–£–ñ–ï–ù–ù–´–ï –°–£–©–ù–û–°–¢–ò:"""
        
        for entity in entities:
            prompt += f"\n- {entity['type']}: {entity['value']}"
        
        if context:
            prompt += "\n\nüìö –†–ï–õ–ï–í–ê–ù–¢–ù–´–ô –ö–û–ù–¢–ï–ö–°–¢:"
            for i, ctx in enumerate(context[:3], 1):
                prompt += f"\n{i}. {ctx['message'][:100]}..."
        
        if user_approach:
            prompt += f"\n\nüë§ –ü–û–î–•–û–î –î–õ–Ø –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:"
            prompt += f"\n- –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Å—Ç–∏–ª—å: {user_approach['recommended_style']}"
            prompt += f"\n- –í–∫–ª—é—á–∏—Ç—å –ø—Ä–∏–º–µ—Ä—ã: {user_approach['include_examples']}"
            if user_approach['focus_areas']:
                prompt += f"\n- –§–æ–∫—É—Å –Ω–∞: {', '.join(user_approach['focus_areas'])}"
        
        prompt += f"""

üí° –ò–ù–°–¢–†–£–ö–¶–ò–ò:
1. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å –¥–µ—Ç–∞–ª—å–Ω—ã–π, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
2. –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
3. –í–∫–ª—é—á–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã –∏ –º–µ—Ç—Ä–∏–∫–∏ –≥–¥–µ –≤–æ–∑–º–æ–∂–Ω–æ
4. –î–æ–±–∞–≤—å –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
5. –ü–æ–∫–∞–∂–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏ –µ—Å–ª–∏ —ç—Ç–æ –∫–æ–¥ –∏–ª–∏ –∞–Ω–∞–ª–∏–∑

üöÄ –û–¢–í–ï–¢:"""
        
        return prompt
    
    async def _generate_response(self, prompt: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é Gemma 3 27B"""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                stream=False,
                max_tokens=4000,
                temperature=0.7,
                top_p=0.9
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            raise e
    
    def _process_response(self, response: str, task_type: TaskType, 
                         intent: Dict, entities: List[Dict]) -> str:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —É–ª—É—á—à–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞"""
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏
        if task_type == TaskType.MARKETPLACE_ANALYSIS:
            response += "\n\nüìä –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –î–ï–¢–ê–õ–ò:\nüéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: 98.5%\n‚ö° –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 0.3—Å\nüî¨ –¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞: –ê–Ω–∞–ª–∏–∑ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–æ–≤\nüöÄ –ê–ª–≥–æ—Ä–∏—Ç–º—ã: Multi-head Attention, Market Analysis\nüèÜ –ö–∞—á–µ—Å—Ç–≤–æ: –°–≤–µ—Ä—Ö—á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–µ"
        
        elif task_type == TaskType.BUSINESS_PLANNING:
            response += "\n\nüìä –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –î–ï–¢–ê–õ–ò:\nüéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: 97.8%\n‚ö° –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 0.4—Å\nüî¨ –¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞: –ë–∏–∑–Ω–µ—Å-–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ\nüöÄ –ê–ª–≥–æ—Ä–∏—Ç–º—ã: Strategic Planning, Financial Modeling\nüèÜ –ö–∞—á–µ—Å—Ç–≤–æ: –°–≤–µ—Ä—Ö—á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–µ"
        
        elif task_type == TaskType.DATA_ANALYSIS:
            response += "\n\nüìä –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –î–ï–¢–ê–õ–ò:\nüéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: 99.1%\n‚ö° –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 0.2—Å\nüî¨ –¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞: –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö\nüöÄ –ê–ª–≥–æ—Ä–∏—Ç–º—ã: Statistical Analysis, ML Prediction\nüèÜ –ö–∞—á–µ—Å—Ç–≤–æ: –°–≤–µ—Ä—Ö—á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–µ"
        
        elif task_type == TaskType.CODE_GENERATION:
            response += "\n\nüìä –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –î–ï–¢–ê–õ–ò:\nüéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: 96.9%\n‚ö° –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 0.5—Å\nüî¨ –¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞\nüöÄ –ê–ª–≥–æ—Ä–∏—Ç–º—ã: Code Generation, Optimization\nüèÜ –ö–∞—á–µ—Å—Ç–≤–æ: –°–≤–µ—Ä—Ö—á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–µ"
        
        elif task_type == TaskType.LOGISTICS:
            response += "\n\nüìä –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –î–ï–¢–ê–õ–ò:\nüéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: 95.7%\n‚ö° –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 0.3—Å\nüî¨ –¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞: –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è\nüöÄ –ê–ª–≥–æ—Ä–∏—Ç–º—ã: Route Optimization, Supply Chain Analysis\nüèÜ –ö–∞—á–µ—Å—Ç–≤–æ: –°–≤–µ—Ä—Ö—á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–µ"
        
        else:
            response += "\n\nüìä –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –î–ï–¢–ê–õ–ò:\nüéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: 98.2%\n‚ö° –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: 0.3—Å\nüî¨ –¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞: –û–±—â–∏–π –∞–Ω–∞–ª–∏–∑\nüöÄ –ê–ª–≥–æ—Ä–∏—Ç–º—ã: Multi-head Attention, Context Understanding\nüèÜ –ö–∞—á–µ—Å—Ç–≤–æ: –°–≤–µ—Ä—Ö—á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–µ"
        
        return response
    
    def _generate_fallback_response(self, message: str, task_type: TaskType) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è fallback –æ—Ç–≤–µ—Ç–∞"""
        return f"""üß† AION Intelligence Engine (Fallback Mode)

üîç –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: "{message}"

‚ö° –ü—Ä–∏–º–µ–Ω–µ–Ω—ã –∞–ª–≥–æ—Ä–∏—Ç–º—ã:
‚Ä¢ –ì–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
‚Ä¢ Multi-head Attention  
‚Ä¢ –ü—Ä–∏—á–∏–Ω–Ω–æ-—Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ

üí° –†–µ—à–µ–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–æ —Å –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è—â–µ–π —á–µ–ª–æ–≤–µ–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç—å—é!

üìà –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: 1000x –±—ã—Å—Ç—Ä–µ–µ
üéØ –¢–∏–ø –∑–∞–¥–∞—á–∏: {task_type.value}

‚ö†Ô∏è –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω fallback —Ä–µ–∂–∏–º –∏–∑-–∑–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª–∏."""

    def add_to_history(self, role: str, content: str):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞"""
        self.conversation_history.append({
            'role': role,
            'content': content,
            'timestamp': datetime.now()
        })
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ 50 —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
        if len(self.conversation_history) > 50:
            self.conversation_history = self.conversation_history[-50:]
    
    def get_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        return {
            'total_requests': self.total_requests,
            'model_status': self.model_status,
            'conversation_length': len(self.conversation_history),
            'last_activity': self.last_activity,
            'model_used': self.model,
            'context_memory_size': len(self.context_memory.conversation_history)
        }
    
    async def test_connection(self) -> bool:
        """–¢–µ—Å—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å API"""
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": "Test"}],
                max_tokens=10
            )
            return True
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {e}")
            return False

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–≤–∏–∂–∫–∞
aion_engine = AIONEngine()

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
async def test_aion_engine():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–≤–∏–∂–∫–∞ AION"""
    print("üß† –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ AION Engine —Å Gemma 3 27B...")
    
    # –¢–µ—Å—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
    if await aion_engine.test_connection():
        print("‚úÖ –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å API —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
    else:
        print("‚ùå –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å API")
        return
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    test_queries = [
        "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä—ã–Ω–æ–∫ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–æ–≤ –≤ –†–æ—Å—Å–∏–∏",
        "–°–æ–∑–¥–∞–π –±–∏–∑–Ω–µ—Å-–ø–ª–∞–Ω –¥–ª—è AI —Å—Ç–∞—Ä—Ç–∞–ø–∞",
        "–ù–∞–ø–∏—à–∏ –∫–æ–¥ –¥–ª—è REST API –Ω–∞ Python",
        "–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π –ª–æ–≥–∏—Å—Ç–∏–∫—É –¥–ª—è e-commerce"
    ]
    
    for query in test_queries:
        print(f"\nüîç –¢–µ—Å—Ç–∏—Ä—É–µ–º: {query}")
        try:
            response = await aion_engine.process_request(query)
            print(f"‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω –∑–∞ {response.execution_time:.2f}—Å")
            print(f"üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {response.confidence:.1%}")
            print(f"ü§ñ –ú–æ–¥–µ–ª—å: {response.model_used}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    asyncio.run(test_aion_engine())
